"""
Core Bitcrusher Audio Processing Engine
Handles all the digital audio destruction magic âš¡
"""

import numpy as np
from scipy import signal
from typing import Tuple, Optional
import threading
import time


class BitCrusher:
    """
    Advanced bitcrusher with multiple algorithms for maximum audio destruction ðŸ”¥
    """
    
    def __init__(self):
        self.sample_rate = 44100
        self.is_processing = False
        self.processing_lock = threading.Lock()
        # Use 64-bit float for better quality and performance
        self.dtype = np.float64
        
    def reduce_bit_depth(self, audio: np.ndarray, bit_depth: int) -> np.ndarray:
        """
        Reduce bit depth for quantization distortion
        
        Args:
            audio: Input audio array
            bit_depth: Target bit depth (1-16)
            
        Returns:
            Bit-reduced audio
        """
        if bit_depth >= 16:
            return audio
            
        # Calculate quantization levels
        levels = 2 ** bit_depth
        max_val = levels - 1
        
        # Normalize to 0-1 range, quantize, then scale back
        normalized = (audio + 1.0) / 2.0
        quantized = np.round(normalized * max_val) / max_val
        
        return (quantized * 2.0) - 1.0
    
    def downsample_and_upsample(self, audio: np.ndarray, factor: float) -> np.ndarray:
        """
        Downsample then upsample for aliasing artifacts
        
        Args:
            audio: Input audio array
            factor: Downsampling factor (1.0 = no change, higher = more crushing)
            
        Returns:
            Processed audio with aliasing artifacts
        """
        if factor <= 1.0:
            return audio
            
        # Calculate new sample rate
        new_rate = int(self.sample_rate / factor)
        
        # Downsample using scipy
        downsampled = signal.resample(audio, int(len(audio) / factor))
        
        # Upsample back to original rate
        upsampled = signal.resample(downsampled, len(audio))
        
        return upsampled
    
    def apply_waveshaping(self, audio: np.ndarray, drive: float = 0.5) -> np.ndarray:
        """
        Apply waveshaping distortion for extra character
        
        Args:
            audio: Input audio array
            drive: Distortion amount (0.0-1.0)
            
        Returns:
            Waveshaped audio
        """
        if drive <= 0.0:
            return audio
            
        # Apply soft clipping with adjustable drive
        driven = audio * (1.0 + drive * 3.0)
        return np.tanh(driven) * 0.8
    
    def add_noise(self, audio: np.ndarray, amount: float = 0.1) -> np.ndarray:
        """
        Add digital noise for extra grit
        
        Args:
            audio: Input audio array
            amount: Noise amount (0.0-1.0)
            
        Returns:
            Audio with added noise
        """
        if amount <= 0.0:
            return audio
            
        noise = np.random.normal(0, amount * 0.1, audio.shape)
        return audio + noise
    
    def process_audio(self, 
                     audio: np.ndarray, 
                     bit_depth: int = 8,
                     downsample_factor: float = 1.0,
                     mix: float = 1.0,
                     waveshape: float = 0.0,
                     noise: float = 0.0) -> np.ndarray:
        """
        Main bitcrushing function with all effects
        
        Args:
            audio: Input audio array
            bit_depth: Target bit depth (1-16)
            downsample_factor: Downsampling factor (1.0+)
            mix: Wet/dry mix (0.0-1.0)
            waveshape: Waveshaping amount (0.0-1.0)
            noise: Noise amount (0.0-1.0)
            
        Returns:
            Processed audio
        """
        with self.processing_lock:
            self.is_processing = True
            
            try:
                # Start with a copy of the original in 64-bit
                processed = audio.astype(self.dtype)
                original = processed.copy()  # Keep original for mix
                
                # Apply bit depth reduction
                processed = self.reduce_bit_depth(processed, bit_depth)
                
                # Apply downsampling/upsampling
                if downsample_factor > 1.0:
                    processed = self.downsample_and_upsample(processed, downsample_factor)
                
                # Apply waveshaping
                if waveshape > 0.0:
                    processed = self.apply_waveshaping(processed, waveshape)
                
                # Add noise
                if noise > 0.0:
                    processed = self.add_noise(processed, noise)
                
                # Apply wet/dry mix with original 64-bit precision
                if mix < 1.0:
                    processed = original * (1.0 - mix) + processed * mix
                
                # Ensure we don't clip
                processed = np.clip(processed, -1.0, 1.0)
                
                # Ensure output is C-contiguous for pygame compatibility
                if not processed.flags['C_CONTIGUOUS']:
                    processed = np.ascontiguousarray(processed)
                
                return processed
                
            finally:
                self.is_processing = False
    
    def process_realtime_chunk(self, 
                              chunk: np.ndarray,
                              bit_depth: int = 8,
                              downsample_factor: float = 1.0,
                              mix: float = 1.0,
                              waveshape: float = 0.0,
                              noise: float = 0.0) -> np.ndarray:
        """
        Process a small chunk for real-time playback
        Optimized for low latency and immediate parameter response
        """
        # Create a copy for processing
        processed = chunk.astype(np.float32, copy=True)
        original = chunk.astype(np.float32, copy=True)
        
        # Quick bit depth reduction - most audible effect
        if bit_depth < 16:
            levels = 2 ** bit_depth
            max_val = levels - 1
            # Normalize, quantize, denormalize
            normalized = (processed + 1.0) / 2.0
            quantized = np.round(normalized * max_val) / max_val
            processed = (quantized * 2.0) - 1.0
        
        # Fast downsampling simulation
        if downsample_factor > 1.0:
            step = max(1, int(downsample_factor))
            if step > 1:
                # Simple hold-and-repeat for aliasing effect
                for i in range(0, len(processed), step):
                    end_idx = min(i + step, len(processed))
                    if i < len(processed):
                        processed[i:end_idx] = processed[i]
        
        # Simple waveshaping
        if waveshape > 0.0:
            intensity = waveshape * 2.0
            processed = np.tanh(processed * intensity) / intensity
        
        # Add noise
        if noise > 0.0:
            noise_data = np.random.normal(0, noise * 0.05, processed.shape).astype(np.float32)
            processed = processed + noise_data
        
        # Apply mix
        if mix < 1.0:
            processed = original * (1.0 - mix) + processed * mix
        
        # Clip and ensure C-contiguous
        result = np.clip(processed, -1.0, 1.0)
        if not result.flags['C_CONTIGUOUS']:
            result = np.ascontiguousarray(result)
            
        return result
    
    def get_presets(self) -> dict:
        """
        Get built-in presets for different styles
        """
        return {
            "subtle": {
                "bit_depth": 12,
                "downsample_factor": 1.5,
                "mix": 0.3,
                "waveshape": 0.1,
                "noise": 0.0
            },
            "retro": {
                "bit_depth": 8,
                "downsample_factor": 2.0,
                "mix": 0.7,
                "waveshape": 0.2,
                "noise": 0.05
            },
            "harsh": {
                "bit_depth": 4,
                "downsample_factor": 4.0,
                "mix": 0.9,
                "waveshape": 0.4,
                "noise": 0.1
            },
            "destroy": {
                "bit_depth": 2,
                "downsample_factor": 8.0,
                "mix": 1.0,
                "waveshape": 0.6,
                "noise": 0.2
            },
            "lofi": {
                "bit_depth": 6,
                "downsample_factor": 3.0,
                "mix": 0.8,
                "waveshape": 0.3,
                "noise": 0.15
            },
            "gameboy": {
                "bit_depth": 4,
                "downsample_factor": 2.5,
                "mix": 1.0,
                "waveshape": 0.1,
                "noise": 0.05
            },
            "telephone": {
                "bit_depth": 3,
                "downsample_factor": 6.0,
                "mix": 1.0,
                "waveshape": 0.5,
                "noise": 0.1
            }
        }
    
    def analyze_audio(self, audio: np.ndarray) -> dict:
        """
        Analyze audio for visualization
        
        Returns:
            Dictionary with analysis data
        """
        return {
            "rms": np.sqrt(np.mean(audio**2)),
            "peak": np.max(np.abs(audio)),
            "length": len(audio),
            "dynamic_range": np.max(audio) - np.min(audio),
            "zero_crossings": len(np.where(np.diff(np.signbit(audio)))[0])
        }
